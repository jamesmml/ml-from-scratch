{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53104103-c56b-468e-bca6-89ada3c8899a",
   "metadata": {},
   "source": [
    "# Machine Learning From Scratch\n",
    "This notebook implements dense neural networks using Python and NumPy without using libraries such as TensorFlow or PyTorch. It demonstrates how to train a NN using forward propagation, backpropagation, and data normalization. Additionally, this notebook demonstrates how to implement a NN to make predictions.\n",
    "\n",
    "This project is part of my exploration of machine learning fundamentals.\n",
    "\n",
    "WARNING: Exception handling was not a focus of this exploration, especially for the multiclass dense NN. For this reason, data must be correctly handled before use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b156936-3e62-4d75-a1db-7f52971896f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199dffdb-1709-43b8-a9c3-7d46690722b2",
   "metadata": {},
   "source": [
    "<h3>Binary Classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63537609-4db8-463a-a161-258752b9cea2",
   "metadata": {},
   "source": [
    "<h4>Project Structure</h4>\n",
    "<li> X - NumPy 2D array, m x n; m training examples, n features </li>\n",
    "<li> y - NumPy 2D array , m x 1; m outputs, 1 columns : column vector </li>\n",
    "<li> W - Python list of numpy 2D arrays (matrices); index of each array corresponds to the index of its respective layer; e.g. of W: n x l matrix, l x l-1 matrix, etc. </li>\n",
    "<li> B - Python list of numpy 2D arrays (row vectors); index of each array corresponds to the index of its respective layer; e.g. of B: 1 x l, 1 x l-1, etc. </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72945e0-dbdb-4817-ad2e-6026d2ee7f1a",
   "metadata": {},
   "source": [
    "<h4>Activation Function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb518b8-abf5-4b62-939c-62b0533e70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Takes a scalar, nd.array\n",
    "    and transforms it via\n",
    "    the sigmoid function\n",
    "    (applied element-wise)\n",
    "\n",
    "    Args:\n",
    "        z : scalar, nd.array\n",
    "\n",
    "    Returns:\n",
    "        An array\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c6687-dfc0-4633-9ee7-4b846619e14b",
   "metadata": {},
   "source": [
    "<h4>Forward Propagation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "231eb688-51ed-4217-a376-b725d50aaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer_forward(inpt, W, B):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Takes the activation/input\n",
    "    of the previous layer and calculates\n",
    "    the current activation\n",
    "\n",
    "    Args:\n",
    "        inpt : Previous activation/input (2D Array - matrix)\n",
    "        W : Weights (2D Array - matrix)\n",
    "        B : Bias (2D Array - row vector)\n",
    "    \n",
    "    Returns:\n",
    "        A : Activation array (2D)\n",
    "    \"\"\"\n",
    "    if not inpt.shape[1] == W.shape[0] or not W.shape[1] == B.shape[1]:\n",
    "        raise ValueError(f\"Array shape mismatch! - inpt: {inpt.shape}, W: {W.shape}, B: {B.shape}\")\n",
    "    z = np.matmul(inpt, W) + B \n",
    "    A = sigmoid(z)\n",
    "    \n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1711d26b-04e5-4fd9-9d5c-f135313a382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W, B, num_layers):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Executes forward propagation\n",
    "    on a dense neural network\n",
    "\n",
    "    Args:\n",
    "        X : Input values (2D Array - matrix)\n",
    "        W : Weights (Python list of 2D Arrays - matrices)\n",
    "        B : Bias (Python list of 2D Arrays - row vectors)\n",
    "        num_layers : # of layers (scalar)\n",
    "    \n",
    "    Returns:\n",
    "        A : Final activation array (2D)\n",
    "        A_list : Python list of activation arrays (2D)\n",
    "    \"\"\"\n",
    "    A_list = []\n",
    "    \n",
    "    for i in range(num_layers): \n",
    "        w = W[i]\n",
    "        b = B[i]\n",
    "        A = dense_layer_forward(X, w, b)\n",
    "        X = A\n",
    "        A_list.append(A)\n",
    "\n",
    "    return A, A_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1cdd9d-acdf-49b4-93fb-54c30c7240d6",
   "metadata": {},
   "source": [
    "<h4>Backpropagation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be708cc-7c19-45d3-b670-2ac42a478c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, W, B, num_layers, A_list, alpha):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Runs through each layer of the\n",
    "    dense neural network, computes\n",
    "    the gradients for W and B, and updates\n",
    "    W and B accordingly\n",
    "    \n",
    "    Args:\n",
    "        X : Input values (2D Array - matrix)\n",
    "        y : Output values (2D Array - column vector)\n",
    "        W : Weights (Python list of 2D Arrays - matrices)\n",
    "        B : Bias (Python list of 2D Arrays - row vectors)\n",
    "        num_layers : # of layers (scalar)\n",
    "        A_list : Python list of activations/inputs (2D Arrays - matrices)\n",
    "        alpha : Learning rate (scalar)\n",
    "    \n",
    "    Returns:\n",
    "        W, B : Python lists of 2D NumPy arrays\n",
    "    \"\"\"\n",
    "    prev_delta = None\n",
    "    \n",
    "    for i in range((num_layers-1), -1, -1): \n",
    "        if i == num_layers - 1:\n",
    "            delta = A_list[i] - y \n",
    "            prev_A = A_list[i-1]\n",
    "        \n",
    "            dL_dW = np.matmul(prev_A.T, delta)\n",
    "        \n",
    "            dL_dB = np.sum(delta, axis = 0, keepdims = True)\n",
    "            \n",
    "            W[i] = W[i] - alpha * dL_dW\n",
    "            B[i] = B[i] - alpha * dL_dB\n",
    "\n",
    "            prev_delta = delta\n",
    "\n",
    "        elif i != 0:\n",
    "            delta = np.matmul(prev_delta, W[i+1].T) \n",
    "            delta = delta * (A_list[i] * (1 - A_list[i]))\n",
    "            dL_dW = np.matmul(A_list[i-1].T, delta)\n",
    "            \n",
    "            dL_dB = np.sum(delta, axis = 0, keepdims = True)\n",
    "            \n",
    "            W[i] = W[i] - alpha * dL_dW\n",
    "            B[i] = B[i] - alpha * dL_dB\n",
    "            \n",
    "            prev_delta = delta\n",
    "\n",
    "        else:\n",
    "            delta = np.matmul(prev_delta, W[i+1].T) \n",
    "            delta = delta * (A_list[i] * (1 - A_list[i]))\n",
    "            dL_dW = np.matmul(X.T, delta)\n",
    "            \n",
    "            dL_dB = np.sum(delta, axis = 0, keepdims = True)\n",
    "            \n",
    "            W[i] = W[i] - alpha * dL_dW\n",
    "            B[i] = B[i] - alpha * dL_dB\n",
    "\n",
    "    \n",
    "    return W, B\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20102238-c9c5-488f-8791-9aafa8107b7e",
   "metadata": {},
   "source": [
    "<h4>NN Training/Testing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ac7ddd-fdf8-4a55-b360-d7adf8f67f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X, y, layer_list, epochs, alpha, seed):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Takes in a set of input data\n",
    "    and returns the parameters\n",
    "    for each layer\n",
    "\n",
    "    Args:\n",
    "        X : Input values (2D Array - matrix)\n",
    "        y : Output values (2D Array - column vector)\n",
    "        layer_list : Python list of # units/layer\n",
    "        epochs : Number of epochs (scalar)\n",
    "        alpha : Learning rate (scalar)\n",
    "        seed : Random seed (scalar)\n",
    "    \n",
    "    Returns:\n",
    "        W, B : Python lists of 2D NumPy arrays\n",
    "    \"\"\"\n",
    "    if not len(layer_list) > 0:\n",
    "        raise ValueError(\"Neural network is not defined!\")\n",
    "    if not type(alpha) == float or type(alpha) == int or not alpha > 0.0:\n",
    "        raise ValueError(\"Learning Rate is invalid\")\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    num_layers = len(layer_list)\n",
    "    \n",
    "    W = []\n",
    "    B = []\n",
    "\n",
    "    prev_unit = None\n",
    "    for idx, unit in enumerate(layer_list):\n",
    "        if idx == 0:\n",
    "            W.append(np.random.rand(X.shape[1], unit))\n",
    "            B.append(np.random.rand(1, unit))\n",
    "            prev_unit = unit\n",
    "        else:\n",
    "            W.append(np.random.rand(prev_unit,unit))\n",
    "            B.append(np.random.rand(1, unit))\n",
    "            prev_unit = unit\n",
    "    \n",
    "    if not X.shape[0] == y.shape[0] or not W[0].shape[0] == X.shape[1] or not B[0].shape[1] == W[0].shape[1]:\n",
    "        raise ValueError(f\"Array shape mismatch! - X: {X.shape}, y: {y.shape}, W_initial: {W[0].shape}, B_initial: {B[0].shape}\")\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        A, A_list = forward_propagation(X, W, B, num_layers)\n",
    "        W, B = backward_propagation(X, y, W, B, num_layers, A_list, alpha)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Status: Epoch {i+1} out of {epochs}\")\n",
    "\n",
    "\n",
    "    \n",
    "    return W, B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9556e4ba-4c29-4226-b713-26eea06d538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_neural_network(X, y, W, B, layer_list):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Uses input data\n",
    "    to classify the data (binary\n",
    "    classification)\n",
    "\n",
    "    Args:\n",
    "        X : Input values (2D Array - matrix)\n",
    "        y : Output values (2D Array - column vector)\n",
    "        W : Weights (Python list of 2D Arrays - matrices)\n",
    "        B : Bias (Python list of 2D Arrays - row vectors)\n",
    "        layer_list : Python list of # units/layer\n",
    "    \n",
    "    Returns:\n",
    "        A : Prediction array (2D)\n",
    "    \"\"\"\n",
    "    num_layers = len(layer_list) \n",
    "    \n",
    "    A, history = forward_propagation(X, W, B, num_layers)\n",
    "    \n",
    "    A = (A>= .5).astype(int)\n",
    "\n",
    "    A = A.reshape(1,-1)\n",
    "\n",
    "    # print(f\"The predictions for the neural network are (output vector was reshaped for formatting): {A}\")\n",
    "\n",
    "    A = A.reshape(-1,1)\n",
    "    \n",
    "    accuracy = np.mean(A == y)\n",
    "\n",
    "    print(f\"The accuracy (%) of the neural network is: {accuracy}\")\n",
    "\n",
    "    return A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fc9d982-2f56-4f03-a8c7-e0db6768f3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Epoch 10 out of 100\n",
      "Status: Epoch 20 out of 100\n",
      "Status: Epoch 30 out of 100\n",
      "Status: Epoch 40 out of 100\n",
      "Status: Epoch 50 out of 100\n",
      "Status: Epoch 60 out of 100\n",
      "Status: Epoch 70 out of 100\n",
      "Status: Epoch 80 out of 100\n",
      "Status: Epoch 90 out of 100\n",
      "Status: Epoch 100 out of 100\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "np.random.seed(68329)\n",
    "\n",
    "X0 = np.random.randn(100, 2) + np.array([-2, -2])\n",
    "y0 = np.zeros((100, 1))\n",
    "\n",
    "X1 = np.random.randn(100, 2) + np.array([2, 2])\n",
    "y1 = np.ones((100, 1))\n",
    "\n",
    "X = np.vstack((X0, X1))  # shape: (200, 2)\n",
    "y = np.vstack((y0, y1))  # shape: (200, 1)\n",
    "\n",
    "layer_list = [10, 5, 3, 1]\n",
    "W, B = train_neural_network(X, y, layer_list, 100, .01, 891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7215301e-1fa8-43a4-b468-67fdac9838a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy (%) of the neural network is: 1.0\n"
     ]
    }
   ],
   "source": [
    "result = predict_neural_network(X, y, W, B, layer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43860bb8-0434-41d1-b2ea-6a83590f00b1",
   "metadata": {},
   "source": [
    "<h3>Multiclass Classification: Handwritten Numbers 0-9</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db571d-ed12-4d86-943f-e6dbe4dfef55",
   "metadata": {},
   "source": [
    "<h4><a href=\"https://www.nist.gov/itl/products-and-services/emnist-dataset\">MNIST Binary</a> â†’ NumPy Arrays</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c98dd52-e745-4ef0-a100-09b949c00750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = idx2numpy.convert_from_file(\"MNIST DATA/gzip/emnist-digits-train-images-idx3-ubyte/emnist-digits-train-images-idx3-ubyte\")\n",
    "train_labels_data = idx2numpy.convert_from_file(\"MNIST DATA/gzip/emnist-digits-train-labels-idx1-ubyte/emnist-digits-train-labels-idx1-ubyte\")\n",
    "# Change the above paths to match the paths of your local files\n",
    "\n",
    "train_images = (train_images.reshape(240000, 784)) / 255.0 # Data normalized by max scaling\n",
    "train_labels_data = train_labels_data.reshape(-1, 1)\n",
    "\n",
    "train_labels = np.zeros((train_labels_data.shape[0], 10))\n",
    "\n",
    "train_labels[np.arange(train_labels_data.shape[0]), train_labels_data.flatten()] = 1 # Matrix is comprised of one-hot row vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03712631-0c56-4421-b716-502d04254ae6",
   "metadata": {},
   "source": [
    "<h3>Dense NN: Softmax for Classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a9ed9-23c9-49b5-bf3c-18a4618f7a96",
   "metadata": {},
   "source": [
    "<h4>Activation Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aae7d874-3469-4fa0-a9de-0a8313c2e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Takes a NumPy array\n",
    "    and transforms it via\n",
    "    the Rectified Linear Unit\n",
    "    activation function\n",
    "\n",
    "    Args:\n",
    "        z : pre-activation (2D NumPy array)\n",
    "\n",
    "    Returns:\n",
    "        2D NumPy array\n",
    "    \"\"\"\n",
    "    return np.maximum(0,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec36c2a2-f2ce-4734-b4a2-9ba0faf1a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_softmax(z):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Takes a NumPy array\n",
    "    and transforms it via the\n",
    "    softmax function; incorporates\n",
    "    numerical stability\n",
    "    \n",
    "    Args:\n",
    "        z : 2D NumPy array\n",
    "\n",
    "    Returns:\n",
    "        2D NumPy array\n",
    "    \"\"\"\n",
    "    shifted_z = z - np.max(z, keepdims = True, axis = 1)\n",
    "    e_z = np.exp(shifted_z)\n",
    "    sm = e_z/np.sum(e_z, keepdims = True, axis = 1)\n",
    "    return sm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a54b78-5d15-4174-9a1a-7d87f547c49e",
   "metadata": {},
   "source": [
    "<h4>Forward Propagation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "562b036e-56ac-4112-8cc8-22b1109d51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop_multiclass(X,W,B):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Executes forward propagation\n",
    "    for a dense neural network,\n",
    "    activation functions are ReLU,\n",
    "    linear\n",
    "    \n",
    "    Args:\n",
    "        X : Training examples (2D NumPy array)\n",
    "        W : Weights list (List of 2D NumPy arrays)\n",
    "        B : Bias list (List of 2D NumPy arrays)\n",
    "\n",
    "    Returns:\n",
    "        z : Pre-activation list (List of 2D NumPy arrays)\n",
    "        a : Activation list (List of 2D NumPy arrays)\n",
    "    \"\"\"\n",
    "    z = []\n",
    "    a = []\n",
    "\n",
    "    num_layers = len(W)\n",
    "\n",
    "    curr_a_i = X\n",
    "\n",
    "    for i in range(num_layers): \n",
    "        z_i = np.matmul(curr_a_i, W[i]) + B[i]\n",
    "        z.append(z_i)\n",
    "        \n",
    "        if i != num_layers - 1:\n",
    "            a_i = ReLU(z_i)\n",
    "            curr_a_i = a_i\n",
    "            a.append(a_i)\n",
    "            \n",
    "        else:\n",
    "            a_i = safe_softmax(z_i)\n",
    "            a.append(a_i)\n",
    "\n",
    "    return z, a\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f41107-8669-46da-9e46-3d7401c8c1d0",
   "metadata": {},
   "source": [
    "<h4>Backpropagation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ec624af-4c42-4771-8cea-a27c650f9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop_multiclass(X,y,W,B,a,z,alpha):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "\n",
    "    Executes backward propagation\n",
    "    for a dense neural network,\n",
    "    updating W,B in-place\n",
    "    (output activation is linear,\n",
    "    hidden activations are ReLU)\n",
    "\n",
    "    Args:\n",
    "        X : Training examples (2D NumPy array)\n",
    "        y : Training values (2D NumPy array)\n",
    "        W : Weights list (List of 2D NumPy arrays)\n",
    "        B : Bias list (List of 2D NumPy arrays)\n",
    "        a : Activation list (List of 2D NumPy arrays)\n",
    "        z : Pre-activation list (List of 2D NumPy arrays)\n",
    "        alpha : Learning rate (int/float)\n",
    "\n",
    "    Returns:\n",
    "        W : Weights list (List of 2D NumPy arrays)\n",
    "        B : Bias list (List of 2D NumPy arrays) \n",
    "    \"\"\"\n",
    "    num_layers = len(W)\n",
    "\n",
    "    prev_delta = None\n",
    "\n",
    "    m = y.shape[0]\n",
    "    for i in range(num_layers - 1, -1, -1):\n",
    "        if (i == num_layers - 1):\n",
    "            delta = a[i] - y\n",
    "            dJ_dW = np.matmul(a[i-1].T, delta * (1/m))\n",
    "            dJ_dB = np.mean(delta, keepdims = True, axis = 0)\n",
    "\n",
    "            W[i] -= dJ_dW * alpha\n",
    "            B[i] -= dJ_dB * alpha\n",
    "\n",
    "            prev_delta = delta\n",
    "\n",
    "        elif (i != 0):\n",
    "            delta = np.matmul(prev_delta, W[i+1].T) * (z[i] > 0).astype(float)\n",
    "            dJ_dW = np.matmul(a[i-1].T, delta * (1/m))\n",
    "            dJ_dB = np.mean(delta, keepdims = True, axis = 0)\n",
    "\n",
    "            W[i] -= dJ_dW * alpha\n",
    "            B[i] -= dJ_dB * alpha\n",
    "\n",
    "            prev_delta = delta\n",
    "\n",
    "        else:\n",
    "            delta = np.matmul(prev_delta, W[i+1].T) * (z[i] > 0).astype(float)\n",
    "            dJ_dW = np.matmul(X.T, delta * (1/m))\n",
    "            dJ_dB = np.mean(delta, keepdims = True, axis = 0)\n",
    "\n",
    "            W[i] -= dJ_dW * alpha\n",
    "            B[i] -= dJ_dB * alpha\n",
    "\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa5727-b100-4f59-a51d-930e5a37cf6f",
   "metadata": {},
   "source": [
    "<h4>NN Training</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b426ad95-7d5c-4ee6-832a-7b01d4985cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_multiclass(X,y,layer_list,epochs,alpha,batch_size):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Trains a neural network via categorical\n",
    "    cross-entropy loss\n",
    "\n",
    "    The parameters W, B are initialized using\n",
    "    He initialization\n",
    "\n",
    "    Args:\n",
    "        X : Training examples (2D NumPy array)\n",
    "        y : Training values (2D NumPy array)\n",
    "        layer_list : \n",
    "        epochs : Number of epochs desired (int)\n",
    "        alpha : Learning rate (int/float)\n",
    "        batch_size : Desired batch size (int)\n",
    "\n",
    "    Returns:\n",
    "        W : Weights list (List of 2D NumPy arrays)\n",
    "        B : Bias list (List of 2D NumPy arrays)\n",
    "    \"\"\"\n",
    "    W = []\n",
    "    B = []\n",
    "\n",
    "    input_dim = X.shape[1]\n",
    "    full_layer_list = [input_dim] + layer_list\n",
    "  \n",
    "    for i in range(len(layer_list)):\n",
    "        w = np.random.randn(full_layer_list[i], full_layer_list[i + 1]) * np.sqrt(2. / full_layer_list[i])\n",
    "        b = np.zeros((1, full_layer_list[i + 1]))\n",
    "        W.append(w)\n",
    "        B.append(b)\n",
    "\n",
    "    m = X.shape[0]\n",
    "    num_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        permutation_array = np.random.permutation(m)\n",
    "        X_shuffled = X[permutation_array]\n",
    "        y_shuffled = y[permutation_array]\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start = batch_idx * batch_size\n",
    "            end = min(start + batch_size, m)\n",
    "            \n",
    "            X_batch = X[start:end]\n",
    "            y_batch = y[start:end]\n",
    "            \n",
    "            z, a = forward_prop_multiclass(X_batch,W,B)\n",
    "            W, B = backward_prop_multiclass(X_batch,y_batch,W,B,a,z,alpha)\n",
    "\n",
    "        if (epoch % 10 == 0):\n",
    "            print(f\"Status: Epoch {epoch} of {epochs}\")\n",
    "        if (epoch == epochs - 1):\n",
    "            print(\"Model training is complete.\")\n",
    "\n",
    "    return W, B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "940cd55d-9713-48c9-951b-447904b4bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Epoch 0 of 50\n",
      "Status: Epoch 10 of 50\n",
      "Status: Epoch 20 of 50\n",
      "Status: Epoch 30 of 50\n",
      "Status: Epoch 40 of 50\n",
      "Model training is complete.\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "layer_list = [512, 256, 128, 10] ; epochs = 50 ; alpha = .001 ; batch_size = 32\n",
    "W, B = train_neural_network_multiclass(train_images,train_labels,layer_list,epochs,alpha,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c319972e-b16a-4ab2-bdb7-8fc652d28a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction\n",
    "def multi_class_predict(X,W,B):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "\n",
    "    Classifies input data based on\n",
    "    trained weight and bias matrices\n",
    "\n",
    "    Args:\n",
    "        X : Training examples (2D NumPy array)\n",
    "        W : Weights list (List of 2D NumPy arrays)\n",
    "        B : Bias list (List of 2D NumPy arrays)\n",
    "\n",
    "    Returns:\n",
    "        yhat : Predicted training values (2D NumPy array)\n",
    "    \"\"\"\n",
    "    z, a = forward_prop_multiclass(X,W,B)\n",
    "    yhat = a[-1]\n",
    "\n",
    "    return yhat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a1673f1-f9e4-4d61-b1ba-0015d7ba26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = multi_class_predict(train_images,W,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3686810-ec5b-4525-87b7-a2e4e0c31e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Test\n",
    "def multi_class_accuracy(y,yhat):\n",
    "    \"\"\"\n",
    "    REQUIRES NUMPY AS NP\n",
    "    \n",
    "    Calculates the accuracy (%)\n",
    "    of a multiclass NN\n",
    "\n",
    "    Args:\n",
    "        y : Training values (2D NumPy array)\n",
    "        yhat : Predicted training values (2D NumPy array)\n",
    "    \n",
    "    Returns:\n",
    "        per_correct : Accuracy of the model (float, 0.0-1.0 inclusive)\n",
    "    \"\"\"\n",
    "    yhat_classes = np.argmax(yhat, axis=1)\n",
    "    y_true_classes = np.argmax(y, axis=1)\n",
    "\n",
    "    correct_predictions = np.sum(yhat_classes == y_true_classes)\n",
    "\n",
    "    percent_correct = correct_predictions / y.shape[0]\n",
    "\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d085727-130e-436d-8863-605f8830da5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NN's accuracy after training is 99.138%\n"
     ]
    }
   ],
   "source": [
    "# Model accuracy after training\n",
    "result = multi_class_accuracy(train_labels,yhat)\n",
    "print(f\"The NN's accuracy after training is {result*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397ad7b-92ff-4b0d-89af-83a538ae6302",
   "metadata": {},
   "source": [
    "<h4>NN Testing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f770c5a-c0a1-4c9b-87b4-c47d2782389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NN's accuracy is: 98.547%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_images = idx2numpy.convert_from_file(\"MNIST DATA/gzip/emnist-digits-test-images-idx3-ubyte/emnist-digits-test-images-idx3-ubyte\")\n",
    "test_labels_data = idx2numpy.convert_from_file(\"MNIST DATA/gzip/emnist-digits-test-labels-idx1-ubyte/emnist-digits-test-labels-idx1-ubyte\")\n",
    "# Change the above paths to match the paths of your local files\n",
    "\n",
    "test_images = (test_images.reshape(-1, 784)) / 255.0\n",
    "test_labels_data = test_labels_data.reshape(-1,1)\n",
    "\n",
    "test_labels = np.zeros((test_labels_data.shape[0],10))\n",
    "\n",
    "test_labels[np.arange(test_labels_data.shape[0]), test_labels_data.flatten()] = 1\n",
    "\n",
    "model_result = multi_class_predict(test_images,W,B)\n",
    "model_accuracy = multi_class_accuracy(test_labels,model_result)\n",
    "\n",
    "print(f\"The NN's accuracy is: {model_accuracy*100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
